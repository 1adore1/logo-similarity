{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ht3btZbWGO5l",
    "outputId": "c5612573-a62e-469c-bd24-cc4be7622337",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gdown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from google.colab import drive\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# drive.mount('/content/drive/')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgdown\u001b[39;00m\n\u001b[1;32m      5\u001b[0m gdown\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m10pHm5N-PFkTZqJ37MfcNpm7iV4Rjt7zz\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerged_dataset.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gdown'"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "import gdown\n",
    "\n",
    "gdown.download(id=\"10pHm5N-PFkTZqJ37MfcNpm7iV4Rjt7zz\", output=\"merged_dataset.zip\", quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('merged_dataset.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.set_per_process_memory_fraction(0.4)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: 2700, Test classes: 300\n",
      "Train: 175403, Val: 20530, Test: 18860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5482/5482 [21:42<00:00,  4.21it/s]\n",
      "100%|██████████| 590/590 [00:53<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/15, train loss: 0.1852 val loss: 0.1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5482/5482 [21:37<00:00,  4.23it/s]\n",
      "100%|██████████| 590/590 [00:52<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/15, train loss: 0.1226 val loss: 0.1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5482/5482 [21:37<00:00,  4.23it/s]\n",
      "100%|██████████| 590/590 [00:53<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/15, train loss: 0.0952 val loss: 0.1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 493/5482 [01:57<20:10,  4.12it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATASET_PATH = 'merged_dataset'\n",
    "\n",
    "all_classes = sorted(os.listdir(DATASET_PATH))\n",
    "\n",
    "train_classes, test_classes = train_test_split(all_classes, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f'train classes: {len(train_classes)}, test classes: {len(test_classes)}')\n",
    "\n",
    "class LogoDataset(Dataset):\n",
    "    def __init__(self, class_list, transform=None):\n",
    "        self.class_list = class_list\n",
    "        self.transform = transform\n",
    "        self.data = {}\n",
    "\n",
    "        for class_id in class_list:\n",
    "            class_path = os.path.join(DATASET_PATH, class_id)\n",
    "            images = [os.path.join(class_path, img) for img in os.listdir(class_path)]\n",
    "            if len(images) > 1: \n",
    "                self.data[class_id] = images\n",
    "        \n",
    "        self.class_ids = list(self.data.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(imgs) for imgs in self.data.values())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        anchor_class = random.choice(self.class_ids)\n",
    "        anchor_img = random.choice(self.data[anchor_class])\n",
    "        positive_img = random.choice(self.data[anchor_class])\n",
    "\n",
    "        negative_class = random.choice([c for c in self.class_ids if c != anchor_class])\n",
    "        negative_img = random.choice(self.data[negative_class])\n",
    "\n",
    "        anchor_img = Image.open(anchor_img).convert(\"RGB\")\n",
    "        positive_img = Image.open(positive_img).convert(\"RGB\")\n",
    "        negative_img = Image.open(negative_img).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            anchor_img = self.transform(anchor_img)\n",
    "            positive_img = self.transform(positive_img)\n",
    "            negative_img = self.transform(negative_img)\n",
    "\n",
    "        return anchor_img, positive_img, negative_img\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = LogoDataset(train_classes, train_transform)\n",
    "test_dataset = LogoDataset(test_classes, val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f'train: {len(train_loader.dataset)}, test: {len(test_loader.dataset)}')\n",
    "\n",
    "class LogoEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim=1024):\n",
    "        super(LogoEncoder, self).__init__()\n",
    "        self.model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, embedding_dim)\n",
    "        self.normalize = nn.functional.normalize\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        return x\n",
    "\n",
    "class TripletLossCosine(nn.Module):\n",
    "    def __init__(self, margin=0.2):\n",
    "        super(TripletLossCosine, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_sim = F.cosine_similarity(anchor, positive)\n",
    "        neg_sim = F.cosine_similarity(anchor, negative)\n",
    "        loss = F.relu(self.margin - pos_sim + neg_sim)\n",
    "        return loss.mean()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LogoEncoder(embedding_dim=1024).to(device)\n",
    "criterion = TripletLossCosine(margin=0.4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    for anchor, positive, negative in tqdm(train_loader):\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "        anchor_embed = model(anchor)\n",
    "        positive_embed = model(positive)\n",
    "        negative_embed = model(negative)\n",
    "\n",
    "        loss = criterion(anchor_embed, positive_embed, negative_embed)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    with torch.no_grad():\n",
    "        for anchor, positive, negative in tqdm(test_loader):\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "    \n",
    "            anchor_embed = model(anchor)\n",
    "            positive_embed = model(positive)\n",
    "            negative_embed = model(negative)\n",
    "    \n",
    "            loss = criterion(anchor_embed, positive_embed, negative_embed)    \n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(test_loader)\n",
    "        \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        \n",
    "    print(f'epoch {epoch+1}/{num_epochs}, train loss: {train_loss:.4f} val loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pkjq40fHiWJl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
